{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from functions import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_data(x, y):\n",
    "    \"\"\"Form (y,tX) to get regression data in matrix form.\"\"\"\n",
    "    num_samples = len(y)\n",
    "    tx = np.c_[np.ones(num_samples), x]\n",
    "    return tx, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    poly = np.ones((len(x), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(x, deg)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "    y: weight\n",
    "    tx: 1+height\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # compute loss by MSE\n",
    "    # ***************************************************\n",
    "    e = y - np.tanh(tx.dot(w))\n",
    "    \n",
    "    return 1/2*np.mean(e**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # ***************************************************\n",
    "    # returns weights\n",
    "    # ***************************************************\n",
    "    a = tx.T.dot(tx)\n",
    "    b = tx.T.dot(y)\n",
    "    w = np.linalg.solve(a, b)\n",
    "    loss = compute_loss(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_predicted_labels(x, w):\n",
    "    y_pred = x.dot(w)\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(predict_labels, x, y, train=True):\n",
    "    total_correct_labels = np.sum(predict_labels == y)\n",
    "    print('Total correct labels in training: {}'.format(total_correct_labels))\n",
    "    if train:\n",
    "        print('Training accuracy: {}'.format((total_correct_labels / x.shape[0]) * 100))\n",
    "    else:\n",
    "        print('Testing accuracy: {}'.format((total_correct_labels / x.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# From this part, we start to load and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train dataset\n",
    "yb, input_data, ids = load_csv_data(\"train.csv\")\n",
    "input_data, _, _ = standardize(input_data)\n",
    "# input_data, _ = build_model_data(input_data, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split train dataset to 2 parts for test and train\n",
    "ratio = 0.7\n",
    "x_train, x_test, y_train, y_test, ids_train, ids_test = split_data(input_data, yb, ids, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175000, 211)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test = build_poly(x_test, 7)\n",
    "tx_train = build_poly(x_train, 7)\n",
    "\n",
    "tx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2997644956487409 0.3000954280448022\n"
     ]
    }
   ],
   "source": [
    "#test least_squares()\n",
    "w, loss = least_squares(y_train, tx_train)\n",
    "print(loss, compute_loss(y_test, tx_test, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct labels in training: 138357\n",
      "Training accuracy: 79.06114285714285\n",
      "Total correct labels in training: 59380\n",
      "Testing accuracy: 79.17333333333333\n"
     ]
    }
   ],
   "source": [
    "training_predict_labels = calculate_predicted_labels(tx_train, w)\n",
    "testing_predict_labels = calculate_predicted_labels(tx_test, w)\n",
    "print_accuracy(training_predict_labels, tx_train, y_train)\n",
    "print_accuracy(testing_predict_labels, tx_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3854638707246176 0.38596765840270747\n"
     ]
    }
   ],
   "source": [
    "#test ridge_regression()\n",
    "w, loss = ridge_regression(y_train, x_train, 0.001)\n",
    "print(loss, compute_loss(y_test,x_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3891811177314048 0.38969699048762146\n"
     ]
    }
   ],
   "source": [
    "#test GD()\n",
    "w_initial = np.zeros(x_train.shape[1])\n",
    "max_iters = 1009\n",
    "gamma = 0.05\n",
    "w, loss = least_squares_GD(y_train, x_train, w_initial, max_iters, gamma)\n",
    "print(loss, compute_loss(y_test,x_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-1d5d3ac76b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2018-ML/ML_course/projects/ml-2018-project1/functions.py\u001b[0m in \u001b[0;36mleast_squares_SGD\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;31m# store w and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2018-ML/ML_course/projects/ml-2018-project1/functions.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# ***************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test SGD()\n",
    "w_initial = np.zeros(x_train.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.05\n",
    "w, loss = least_squares_SGD(y_train, x_train, w_initial, max_iters, gamma)\n",
    "print(loss, compute_loss(y_test,x_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cross validatiaon\n",
    "from plots import cross_validation_visualization\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 1\n",
    "    degree = 2\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # ***************************************************\n",
    "    for lambda_ in lambdas:\n",
    "        mse_tr_sum = 0.\n",
    "        mse_te_sum = 0.\n",
    "        for k in range(k_fold):\n",
    "            mse_tr, mse_te = cross_validation(y_train, x_train, k_indices, k, lambda_ ,degree)\n",
    "            mse_tr_sum += mse_tr\n",
    "            mse_te_sum += mse_te\n",
    "        rmse_tr.append(np.sqrt(2*np.divide(mse_tr_sum, k_fold)))\n",
    "        rmse_te.append(np.sqrt(2*np.divide(mse_te_sum, k_fold)))\n",
    "    cross_validation_visualization(lambdas, np.array(rmse_tr), np.array(rmse_te))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: degree\n",
    "    # ***************************************************\n",
    "#     for degree in range(19):\n",
    "#         mse_tr_sum = 0.\n",
    "#         mse_te_sum = 0.\n",
    "#         for k in range(k_fold):\n",
    "#             mse_tr, mse_te = cross_validation(y, x, k_indices, k, 0.01 ,degree)\n",
    "#             mse_tr_sum += mse_tr\n",
    "#             mse_te_sum += mse_te\n",
    "#         rmse_tr.append(np.sqrt(2*np.divide(mse_tr_sum, k_fold)))\n",
    "#         rmse_te.append(np.sqrt(2*np.divide(mse_te_sum, k_fold)))\n",
    "    \n",
    "#     cross_validation_visualization(range(19), np.array(rmse_tr), np.array(rmse_te))\n",
    "\n",
    "#cross_validation_demo()\n",
    "t = build_poly(x_train, 1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 31)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 5, 0, 7, 2, 3, 6])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = x[k_indices[k,:]]\n",
    "    y_test = y[k_indices[k,:]]\n",
    "    for it in range(k_indices.shape[0]):\n",
    "        if it!= k:\n",
    "            x_train.extend(x[k_indices[it, :]])\n",
    "            y_train.extend(y[k_indices[it, :]])\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form data with polynomial degree: TODO\n",
    "    # ***************************************************\n",
    "    tx_train = build_poly(x_train, degree)\n",
    "    tx_test = build_poly(x_test, degree)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    print(len(x_train), x_train)\n",
    "    w = ridge_regression(y_train, x_train, lambda_)\n",
    "    print(len(w))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate the loss for train and test data: TODO\n",
    "    # ***************************************************\n",
    "    print(y_train, tx_train, len(w))\n",
    "    print(y_test.shape, tx_test.shape, len(w))\n",
    "    loss_tr = compute_loss(y_train, tx_train, w)\n",
    "    loss_te = compute_loss(y_test, tx_test, w)\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
